{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoyerMoore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCTAGCTCTACGAGTCTA\n",
    "# TCAA\n",
    "p = 'TCAA'\n",
    "p_bm = BoyerMoore(p)  #BoyerMoore(p, alphabet='ACGT')\n",
    "p_bm.bad_character_rule(2, 'T') # mismatch en offset 2 (T-A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCTAGCTCTACGAGTCTA\n",
    "# ACTA\n",
    "p = 'ACTA'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "p_bm.good_suffix_rule(0) #mismatch en offset 0 (G-A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACACGCTCTACGAGTCTA\n",
    "# ACAC\n",
    "p = 'ACAC'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "p_bm.match_skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10,-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 'GCTAGCTCTACGAGTCTA'\n",
    "p = 'TCTA'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 14]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boyer_moore(p, p_bm, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substring Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# naive is online\n",
    "# BoyerMoore is online\n",
    "# Web-query is offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        ''' Create index from all substrings of size 'length' '''\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    \n",
    "    def query(self, p):\n",
    "        ''' Return index hits for first k-mer of P '''\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def queryIndex(p, t, index):\n",
    "    k = index.k\n",
    "    offsets = []\n",
    "    for i in index.query(p):\n",
    "        if p[k:] == t[i+k:i+len(p)]:  # verify that rest of P matches\n",
    "            offsets.append(i)\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 'ACTTGGAGATCTTTGAGGCTAGGTATTCGGGATCGAAGCTCATTTCGGGGATCGATTACGATATGGTGGGTATTCGGGA'\n",
    "p = 'GGTATTCGGGA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Index object at 0x7f9af6e6e150>\n"
     ]
    }
   ],
   "source": [
    "index = Index(t, 4)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 68]\n"
     ]
    }
   ],
   "source": [
    "print(queryIndex(p, t, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGTATTCGGG'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[68:78]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet='ACGT')\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5]\n"
     ]
    }
   ],
   "source": [
    "p = 'AACTTG'\n",
    "t = 'CACTTAATTTG'\n",
    "print(approximate_match(p, t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AATTTG\n"
     ]
    }
   ],
   "source": [
    "print(t[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUIZ 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t: 'GGCTATAATGCGTA'\n",
    "# p:   TAATAAA\n",
    "t = 'GGCTATAATGCGTA'\n",
    "p = 'TAATAAA'\n",
    "p_bm = BoyerMoore(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_bm.bad_character_rule(4, 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'TAATTAA'\n",
    "p_bm = BoyerMoore(p)\n",
    "p_bm.good_suffix_rule(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boyer_moore(p, p_bm, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUIZ 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement naive_with_counts by extending naive function\n",
    "#from naive_with_counts import naive_with_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naiveHamming(p, t, maxDistance):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        nmm = 0\n",
    "        match = True\n",
    "        counts= []\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                nmm += 1\n",
    "                counts.append(j)\n",
    "                if nmm > maxDistance:\n",
    "                    break\n",
    "        if nmm <= maxDistance:\n",
    "            occurrences.append(i)\n",
    "    return occurrences, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 17], [0, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'TCGCGCAAATTATAGACTCTAGCATCAGCGATAGGCTAGCTGAGCAGATACCATAGTCAGTAGATGACGATAGACAGTA'\n",
    "p = 'TCGAGC'\n",
    "naiveHamming(p, t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_with_counts(p, t):\n",
    "    occurrences = []\n",
    "    aligs = (len(t)-len(p)+1)\n",
    "    counts = 0\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] == p[j]:\n",
    "                counts += 1\n",
    "            if t[i+j] != p[j]:\n",
    "                counts += 1\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "    return occurrences, aligs, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 4], 5, 9)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'TCGATCG'\n",
    "p = 'TCG'\n",
    "naive_with_counts(p, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([40], 41, 46)\n"
     ]
    }
   ],
   "source": [
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 19], 20, 35)\n"
     ]
    }
   ],
   "source": [
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-07-05 23:09:32--  http://d28rh4a8wq0iu5.cloudfront.net/ads1/code/bm_preproc.py\n",
      "Resolving d28rh4a8wq0iu5.cloudfront.net (d28rh4a8wq0iu5.cloudfront.net)... 54.192.55.61, 54.192.55.20, 54.192.55.177, ...\n",
      "Connecting to d28rh4a8wq0iu5.cloudfront.net (d28rh4a8wq0iu5.cloudfront.net)|54.192.55.61|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9400 (9,2K) [application/octet-stream]\n",
      "Saving to: ‘bm_preproc.py’\n",
      "\n",
      "bm_preproc.py       100%[===================>]   9,18K  --.-KB/s    in 0,005s  \n",
      "\n",
      "2017-07-05 23:09:33 (1,75 MB/s) - ‘bm_preproc.py’ saved [9400/9400]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://d28rh4a8wq0iu5.cloudfront.net/ads1/code/bm_preproc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement boyer_moore_with_counts by extending boyer_moore function\n",
    "## from bm_with_counts import boyer_moore_with_counts\n",
    "from bm_preproc import BoyerMoore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    counts = 0\n",
    "    align = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] == t[i+j]:\n",
    "                counts += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                counts += 1\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "        align.append(i)\n",
    "    return occurrences, len(align), counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([40], 12, 15)\n"
     ]
    }
   ],
   "source": [
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 19], 5, 18)\n"
     ]
    }
   ],
   "source": [
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-07-05 23:16:07--  http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta\n",
      "Resolving d28rh4a8wq0iu5.cloudfront.net (d28rh4a8wq0iu5.cloudfront.net)... 52.84.133.160, 52.84.133.213, 52.84.133.236, ...\n",
      "Connecting to d28rh4a8wq0iu5.cloudfront.net (d28rh4a8wq0iu5.cloudfront.net)|52.84.133.160|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 810105 (791K) [application/octet-stream]\n",
      "Saving to: ‘chr1.GRCh38.excerpt.fasta’\n",
      "\n",
      "chr1.GRCh38.excerpt 100%[===================>] 791,12K  1,45MB/s    in 0,5s    \n",
      "\n",
      "2017-07-05 23:16:09 (1,45 MB/s) - ‘chr1.GRCh38.excerpt.fasta’ saved [810105/810105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTGAATGCTGAAATCAGCAGGTAATATATGATAATAGAGAAAGCTATCCCGAAGGTGCATAGGTCAACAATACTTGAGCCTAACTCAGTAGATCCTAAAA'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # ignore header line with genome information\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "    return genome\n",
    "genome = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "genome[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([56922], 799954, 984143)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 y 2\n",
    "t = genome\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "naive_with_counts(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([56922], 127974, 165191)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "p_bm = BoyerMoore(p)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([56922], 127974, 165191)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boyer_moore_with_counts(p, p_bm, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56922]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boyer_moore(p, p_bm, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet='ACGT')\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        ''' Create index from all substrings of size 'length' '''\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    \n",
    "    def query(self, p):\n",
    "        ''' Return index hits for first k-mer of P '''\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def queryIndex(p, t, index):\n",
    "    k = index.k\n",
    "    offsets = []\n",
    "    for i in index.query(p):\n",
    "        if p[k:] == t[i+k:i+len(p)]:  # verify that rest of P matches\n",
    "            offsets.append(i)\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = Index(t, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 262042, 364263, 657496, 717706]\n"
     ]
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "print(queryIndex(p, t, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84641, 160162, 635931, 747359, 273669, 147558, 364263, 681737, 717706, 465647, 429299, 657496, 160729, 56922, 724927, 191452, 262042, 551134, 421221]\n"
     ]
    }
   ],
   "source": [
    "print(approximate_match(p, t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_2mm(p, t):\n",
    "    occurrences = []\n",
    "    \n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        cross =0\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                cross += 1\n",
    "                match = False\n",
    "                \n",
    "        if cross <= 2:\n",
    "          occurrences.append(i)\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 84641, 147558, 160162, 160729, 191452, 262042, 273669, 364263, 421221, 429299, 465647, 551134, 635931, 657496, 681737, 717706, 724927, 747359]\n"
     ]
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "print(naive_2mm(p, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndexApproximate_match(p, t, n):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    p_idx = Index(t, segment_length)\n",
    "    idx_hits = 0\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        matches = p_idx.query(p[start:end])\n",
    "        \n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            idx_hits += 1\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            \n",
    "            mismatches = 0\n",
    "            \n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), idx_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([84641, 160162, 635931, 747359, 273669, 147558, 364263, 681737, 717706, 465647, 429299, 657496, 160729, 56922, 724927, 191452, 262042, 551134, 421221], 90)\n"
     ]
    }
   ],
   "source": [
    "print(IndexApproximate_match(p, t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate_match_subseq(p, t, n, ival):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    p_idx = SubseqIndex(t, segment_length, ival)\n",
    "    idx_hits = 0\n",
    "    for i in range(n+1):\n",
    "        start = i\n",
    "        matches = p_idx.query(p[start:])\n",
    "        \n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            idx_hits += 1\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            \n",
    "            mismatches = 0\n",
    "            \n",
    "            for j in range(0, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), idx_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([84641,\n",
       "  160162,\n",
       "  273669,\n",
       "  147558,\n",
       "  364263,\n",
       "  421221,\n",
       "  681737,\n",
       "  717706,\n",
       "  724927,\n",
       "  465647,\n",
       "  429299,\n",
       "  657496,\n",
       "  160729,\n",
       "  56922,\n",
       "  635931,\n",
       "  191452,\n",
       "  262042,\n",
       "  551134,\n",
       "  747359],\n",
       " 79)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "approximate_match_subseq(p, t, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.dictIndex = {}\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:self.ival], i))  # add (subseq, offset)\n",
    "            if self.dictIndex.has_key(t[i:i+self.span:self.ival]):\n",
    "                self.dictIndex[t[i:i+self.span:self.ival]].append(i)\n",
    "            else:\n",
    "                self.dictIndex[t[i:i+self.span:self.ival]] = [i]\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "        #print \"built index\", self.index\n",
    "        #print \"dict index\", self.dictIndex\n",
    "    \n",
    "    def get_subseq(self, p):\n",
    "        return [p[i:i+self.span:self.ival] for i in range(len(p) - self.span + 1)]  # add (subseq, offset)\n",
    "\n",
    "    def queryDictIndex(self, p):\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        if len(subseq) != self.k:\n",
    "            return []\n",
    "\n",
    "        #print \"input is: '{0}' (length={1}). Querying for: '{2}' (length= {3})\".format(p, len(p), subseq, len(subseq))\n",
    "        \n",
    "        #print \"dict index\", self.dictIndex\n",
    "        if subseq in self.dictIndex.keys():\n",
    "            return self.dictIndex[subseq]\n",
    "        else:\n",
    "           return []\n",
    "\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        import bisect\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        #print \"input is: '{0}' (length={1}). Querying for: '{2}' (length= {3})\".format(p, len(p), subseq, len(subseq))\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                print \"'\", self.index[i][0], \"' != '\", subseq, \"'\"\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n"
     ]
    }
   ],
   "source": [
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_subseq(p, t, subseq_ind):\n",
    "    \"\"\"Write a function that, given a length-24 pattern P and given a SubseqIndex object built with k = 8 and ival = 3, \n",
    "    finds all approximate occurrences of P within T with up to 2 mismatches.\"\"\"\n",
    "    #number of mistmatches = 2, so we need to split into 3 (2+1)\n",
    "    mistmatches_allowed = 2\n",
    "    num_segments_required = mistmatches_allowed + 1\n",
    "    \n",
    "    pattern_size = 24\n",
    "\n",
    "    reads, qualities = readFastq('chr1.GRCh38.excerpt.fasta')\n",
    "    consolidated_read = ''.join([read for read in reads])\n",
    "\n",
    "    #p_segments = [ p[i:] for i in range(0,  pattern_size / subseq_ind.ival) ]\n",
    "    p_segments = []\n",
    "    for i in range(0,  pattern_size):\n",
    "        if len(p[i::subseq_ind.ival]) == subseq_ind.k:\n",
    "            p_segments.append(p[i:])\n",
    "        else:\n",
    "            break\n",
    "    #print p_segments\n",
    "\n",
    "    #print [subseq_ind.get_subseq(segment) for segment in p_segments]\n",
    "    checksize = reduce(lambda x,y : x and y, [map(lambda x: len(x)==8, subseq_ind.get_subseq(segment)) for segment in p_segments])[0]\n",
    "    assert checksize\n",
    "    \n",
    "    hits_lists = []\n",
    "    hits_per_segment = {}\n",
    "    i = 0\n",
    "    index_hits = 0\n",
    "    segment_number = 0\n",
    "    for segment in p_segments:\n",
    "        \n",
    "        #hits = subseq_ind.query(segment)\n",
    "        hits = subseq_ind.queryDictIndex(segment)\n",
    "        i += 1\n",
    "        #print \"hits: \", hits\n",
    "        index_hits += 1\n",
    "        if len(hits) > 0:\n",
    "            #print segment, hits\n",
    "            hits_lists.append(hits)\n",
    "            hits_per_segment[segment_number] = set([hit-segment_number for hit in hits])\n",
    "        segment_number += 1\n",
    "    #print hits_per_segment\n",
    "\n",
    "    #reduce:\n",
    "    reduced_hits = set()\n",
    "    for i in range(len(hits_per_segment)):\n",
    "        intersect = hits_per_segment[i].intersection(hits_per_segment[(i+1)%len(hits_per_segment)])\n",
    "        if len(intersect) > 0 : \n",
    "            for item in intersect:\n",
    "                reduced_hits.add(item)\n",
    "    \n",
    "    return sorted(reduced_hits), index_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 'to-morrow and to-morrow and to-morrow creeps in this petty pace'\n",
    "p = 'to-morrow and to-morrow '\n",
    "subseq_ind = SubseqIndex(t, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFastq(filename):\n",
    "    sequences = []\n",
    "    qualities = []\n",
    "    with open(filename) as fh:\n",
    "        while True:\n",
    "            fh.readline()  # skip name line\n",
    "            seq = fh.readline().rstrip()  # read base sequence\n",
    "            fh.readline()  # skip placeholder line\n",
    "            qual = fh.readline().rstrip() # base quality line\n",
    "            if len(seq) == 0:\n",
    "                break\n",
    "            sequences.append(seq)\n",
    "            qualities.append(qual)\n",
    "    return sequences, qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences, num_index_hits = query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 14]\n"
     ]
    }
   ],
   "source": [
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(num_index_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "\n",
    "#number of mistmatches = 2, so we need to split into 3 (2+1)\n",
    "    mistmatches_allowed = 2\n",
    "    num_segments_required = mistmatches_allowed + 1\n",
    "    k_mer_size = 8\n",
    "    pattern_size = 24\n",
    "    ival = 3\n",
    "\n",
    "    reads, qualities = readFastq('chr1.GRCh38.excerpt.fasta')\n",
    "    t = ''.join([read for read in reads])\n",
    "\n",
    "    subseq_ind = SubseqIndex(t, k_mer_size, ival)\n",
    "    return query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "subseq_ind = SubseqIndex(t, 8, 3)\n",
    "query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6():\n",
    "    p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "\n",
    "    #number of mistmatches = 2, so we need to split into 3 (2+1)\n",
    "    mistmatches_allowed = 2\n",
    "    num_segments_required = mistmatches_allowed + 1\n",
    "    k_mer_size = 8\n",
    "    pattern_size = 24\n",
    "    ival = 3\n",
    "\n",
    "    reads, qualities = readFastq('chr1.GRCh38.excerpt.fasta')\n",
    "    t = ''.join([read for read in reads])\n",
    "\n",
    "    subseq_ind = SubseqIndex(t, k_mer_size, ival)\n",
    "    return query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36918, 116447] 3\n"
     ]
    }
   ],
   "source": [
    "occurrences, num_index_hits = question6()\n",
    "print occurrences, num_index_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-07-06 01:08:01--  http://www.gutenberg.org/ebooks/1110.txt.utf-8\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: http://www.gutenberg.org/cache/epub/1110/pg1110.txt [following]\n",
      "--2017-07-06 01:08:01--  http://www.gutenberg.org/cache/epub/1110/pg1110.txt\n",
      "Reusing existing connection to www.gutenberg.org:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 145418 (142K) [text/plain]\n",
      "Saving to: ‘1110.txt.utf-8’\n",
      "\n",
      "1110.txt.utf-8      100%[===================>] 142,01K   256KB/s    in 0,6s    \n",
      "\n",
      "2017-07-06 01:08:02 (256 KB/s) - ‘1110.txt.utf-8’ saved [145418/145418]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# King John by William Shakespeare\n",
    "!wget http://www.gutenberg.org/ebooks/1110.txt.utf-8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t = open('1110.txt.utf-8').read()\n",
    "p = 'English measure backward'\n",
    "subseq_ind = SubseqIndex(t, 8, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occurrences, num_index_hits = query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 84641, 147558, 160729, 191452, 262042, 273669, 364263, 429299, 465647, 635931, 657496, 681737, 717706, 724927, 747359]\n"
     ]
    }
   ],
   "source": [
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(num_index_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subseq_ind = SubseqIndex(t, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
